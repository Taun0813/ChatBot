# AI Agent System - Hybrid Orchestrator

Há»‡ thá»‘ng AI Agent thÃ´ng minh vá»›i **Hybrid Orchestrator** káº¿t há»£p rule-based vÃ  ML-based routing, sá»­ dá»¥ng dataset thá»±c táº¿ vá»›i 27,000+ sáº£n pháº©m Ä‘iá»‡n thoáº¡i.

## ğŸš€ TÃ­nh nÄƒng chÃ­nh

- **ğŸ¤– Hybrid Orchestrator**: Káº¿t há»£p rule-based + ML-based routing (accuracy 85-95%)
- **ğŸ“Š Real Dataset**: 27,000+ sáº£n pháº©m Ä‘iá»‡n thoáº¡i thá»±c táº¿ tá»« OnePlus, Samsung, Apple, Xiaomi, etc.
- **ğŸ” RAG (Retrieval-Augmented Generation)**: Semantic search vá»›i Pinecone vector database
- **ğŸ’¬ Há»™i thoáº¡i thÃ´ng minh**: TÆ°Æ¡ng tÃ¡c tá»± nhiÃªn vá»›i context-aware routing
- **ğŸ”Œ TÃ­ch há»£p API**: Káº¿t ná»‘i vá»›i cÃ¡c dá»‹ch vá»¥ bÃªn ngoÃ i (Ä‘Æ¡n hÃ ng, thanh toÃ¡n, báº£o hÃ nh)
- **ğŸ‘¤ CÃ¡ nhÃ¢n hÃ³a**: Há»c há»i tá»« hÃ nh vi ngÆ°á»i dÃ¹ng vÃ  Ä‘Æ°a ra gá»£i Ã½ phÃ¹ há»£p
- **ğŸ”„ Multi-model support**: Há»— trá»£ nhiá»u LLM (Gemini, Groq, Ollama, OpenAI, Claude)
- **âš¡ Caching**: Há»‡ thá»‘ng cache thÃ´ng minh vá»›i Redis vÃ  Memory cache
- **ğŸ“ˆ Monitoring**: Theo dÃµi hiá»‡u suáº¥t vÃ  metrics real-time vá»›i dashboard chi tiáº¿t
- **ğŸ¯ Training & Fine-tuning**: Fine-tune model cho domain e-commerce vá»›i data pipeline hoÃ n chá»‰nh

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
ai_agent/
â”‚â”€â”€ app.py                     # Entry point FastAPI
â”‚â”€â”€ config.py                  # Configuration management
â”‚â”€â”€ requirements.txt           # Python dependencies
â”‚
â”œâ”€â”€ core/                      # Core logic (Hybrid Orchestrator)
â”‚   â”‚â”€â”€ models/                # Agent models
â”‚   â”‚   â”‚â”€â”€ __init__.py
â”‚   â”‚   â”‚â”€â”€ base_agent.py      # Base agent class
â”‚   â”‚   â”‚â”€â”€ rag_agent.py       # RAG-specific agent
â”‚   â”‚   â”‚â”€â”€ conversation_agent.py # Conversation agent
â”‚   â”‚   â”‚â”€â”€ api_agent.py       # API integration agent
â”‚   â”‚   â”‚â”€â”€ orchestrator.py    # Agent orchestrator
â”‚   â”‚â”€â”€ router.py              # Hybrid Orchestrator (Rule-based + ML-based)
â”‚   â”‚â”€â”€ rag_model.py           # RAG model implementation
â”‚   â”‚â”€â”€ interaction_model.py   # Conversation model
â”‚   â”‚â”€â”€ api_model.py           # API model
â”‚   â”‚â”€â”€ personalization_model.py # Personalization model
â”‚   â”‚â”€â”€ prompts.py             # Prompt templates
â”‚
â”œâ”€â”€ adapters/                  # Adapter layer (plug-and-play)
â”‚   â”‚â”€â”€ model_loader/          # Model loaders
â”‚   â”‚   â”‚â”€â”€ base_loader.py     # Base loader
â”‚   â”‚   â”‚â”€â”€ gemini_loader.py   # Google Gemini
â”‚   â”‚   â”‚â”€â”€ groq_loader.py     # Groq API
â”‚   â”‚   â”‚â”€â”€ ollama_loader.py   # Ollama local
â”‚   â”‚   â”‚â”€â”€ openai_loader.py   # OpenAI GPT
â”‚   â”‚   â”‚â”€â”€ claude_loader.py   # Claude
â”‚   â”‚â”€â”€ pinecone_client.py     # Pinecone vector DB
â”‚
â”œâ”€â”€ cache/                     # Caching layer
â”‚   â”‚â”€â”€ redis_cache.py         # Redis cache
â”‚   â”‚â”€â”€ memory_cache.py        # In-memory cache
â”‚   â”‚â”€â”€ cache_manager.py       # Cache manager
â”‚
â”œâ”€â”€ monitoring/                # Monitoring & observability
â”‚   â”‚â”€â”€ metrics.py             # Metrics collection
â”‚   â”‚â”€â”€ health_check.py        # Health monitoring
â”‚   â”‚â”€â”€ tracing.py            # Request tracing
â”‚
â”œâ”€â”€ personalization/           # Personalization layer
â”‚   â”‚â”€â”€ profile_manager.py     # User profile management
â”‚   â”‚â”€â”€ recommender.py         # Product recommendations
â”‚   â”‚â”€â”€ rl_feedback.py         # Reinforcement learning
â”‚
â”œâ”€â”€ services/                  # Microservices integration
â”‚   â”‚â”€â”€ product_service.py     # Product API
â”‚   â”‚â”€â”€ order_service.py       # Order API
â”‚   â”‚â”€â”€ payment_service.py     # Payment API
â”‚   â”‚â”€â”€ warranty_service.py    # Warranty API
â”‚   â”‚â”€â”€ mock/                  # Mock services
â”‚   â”‚   â”‚â”€â”€ mock_order.json
â”‚   â”‚   â”‚â”€â”€ mock_warranty.json
â”‚   â”‚   â”‚â”€â”€ mock_payment.json
â”‚
â”œâ”€â”€ data/                      # Data management
â”‚   â”‚â”€â”€ ingest.py              # Data ingestion (supports real dataset)
â”‚   â”‚â”€â”€ process_dataset.py     # Dataset processing
â”‚   â”‚â”€â”€ processed/             # Processed data
â”‚   â”‚â”€â”€ profiles/              # User profiles
â”‚   â”‚â”€â”€ schema/                # Data schemas
â”‚
â”œâ”€â”€ training/                  # Model training & fine-tuning
â”‚   â”‚â”€â”€ dataset/               # Real dataset
â”‚   â”‚   â”‚â”€â”€ dataset.json       # 27,000+ real phone products
â”‚   â”‚â”€â”€ prepare_data.py        # E-commerce data preparation & normalization
â”‚   â”‚â”€â”€ finetune.py           # Model fine-tuning vá»›i PEFT/LoRA
â”‚   â”‚â”€â”€ evaluate.py           # Comprehensive model evaluation
â”‚   â”‚â”€â”€ checkpoints/          # Trained model checkpoints
â”‚
â”œâ”€â”€ utils/                     # Utilities
â”‚   â”‚â”€â”€ logger.py              # Logging utilities
â”‚   â”‚â”€â”€ helpers.py             # Helper functions
â”‚
â””â”€â”€ tests/                     # Unit tests
    â”‚â”€â”€ test_router.py
    â”‚â”€â”€ test_rag_model.py
    â”‚â”€â”€ test_interaction_model.py
    â”‚â”€â”€ test_api_model.py
    â”‚â”€â”€ test_personalization.py
```

## ğŸ› ï¸ CÃ i Ä‘áº·t

### 1. Clone repository
```bash
git clone <repository-url>
cd ai_agent
```

### 2. Táº¡o virtual environment
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate     # Windows
```

### 3. CÃ i Ä‘áº·t dependencies

#### TÃ¹y chá»n 1: CÃ i Ä‘áº·t Ä‘áº§y Ä‘á»§ (khuyáº¿n nghá»‹)
```bash
pip install -r requirements.txt
```

#### TÃ¹y chá»n 2: CÃ i Ä‘áº·t tá»‘i thiá»ƒu (chá»‰ core features)
```bash
pip install fastapi uvicorn pydantic pydantic-settings google-generativeai pinecone-client redis httpx python-dotenv psutil
```

#### TÃ¹y chá»n 3: CÃ i Ä‘áº·t cho development
```bash
pip install -r requirements.txt black isort flake8 mypy pytest pytest-asyncio pytest-cov
```

### 4. Cáº¥u hÃ¬nh environment
```bash
cp env.example .env
# Chá»‰nh sá»­a .env vá»›i API keys cá»§a báº¡n
# QUAN TRá»ŒNG: Cáº§n cÃ³ PINECONE_API_KEY Ä‘á»ƒ sá»­ dá»¥ng vector database
```

### 5. Khá»Ÿi táº¡o dá»¯ liá»‡u vá»›i dataset thá»±c táº¿
```bash
# Load 27,000+ sáº£n pháº©m Ä‘iá»‡n thoáº¡i thá»±c táº¿ vÃ o Pinecone
python init_data.py
```

### 6. Cháº¡y á»©ng dá»¥ng
```bash
python app.py
```

## ğŸ“¦ Requirements

### CÃ¡c file requirements

1. **`requirements.txt`** - CÃ i Ä‘áº·t Ä‘áº§y Ä‘á»§ (khuyáº¿n nghá»‹)
   - Táº¥t cáº£ AI APIs (Gemini, Groq, Ollama, OpenAI, Claude)
   - Vector database (Pinecone cloud only)
   - Caching (Redis, Memory cache)
   - Monitoring & observability
   - Personalization & ML
   - Development tools

2. **`requirements-minimal.txt`** - CÃ i Ä‘áº·t tá»‘i thiá»ƒu
   - Chá»‰ core features cáº§n thiáº¿t
   - Free APIs (Gemini, Groq, Ollama)
   - FAISS vector database
   - Redis caching
   - KÃ­ch thÆ°á»›c: ~500MB

3. **`requirements-dev.txt`** - Development
   - Bao gá»“m táº¥t cáº£ requirements.txt
   - Testing tools (pytest, coverage)
   - Code quality (black, flake8, mypy)
   - Debugging tools
   - Documentation tools

### So sÃ¡nh kÃ­ch thÆ°á»›c cÃ i Ä‘áº·t

| File | KÃ­ch thÆ°á»›c | Thá»i gian cÃ i Ä‘áº·t | TÃ­nh nÄƒng |
|------|------------|-------------------|-----------|
| requirements-minimal.txt | ~500MB | 2-3 phÃºt | Core only |
| requirements.txt | ~2GB | 5-10 phÃºt | Full features |
| requirements-dev.txt | ~2.5GB | 8-15 phÃºt | Full + Dev tools |

## ğŸ”§ Cáº¥u hÃ¬nh

### API Keys (Miá»…n phÃ­)
- **Gemini API**: Láº¥y tá»« [Google AI Studio](https://makersuite.google.com/app/apikey)
- **Groq API**: Láº¥y tá»« [Groq Console](https://console.groq.com/)
- **Ollama**: CÃ i Ä‘áº·t local tá»« [Ollama.ai](https://ollama.ai/)

### Environment Variables
```bash
# Free APIs
GEMINI_API_KEY=your_gemini_api_key
GROQ_API_KEY=your_groq_api_key
OLLAMA_BASE_URL=http://localhost:11434

# Optional APIs
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
PINECONE_API_KEY=your_pinecone_api_key

# Configuration
MODEL_LOADER_BACKEND=gemini  # gemini, groq, ollama, openai, claude
ENABLE_PERSONALIZATION=true
ENABLE_RECOMMENDATIONS=true
ENABLE_RL_LEARNING=true
```

## ğŸš€ Sá»­ dá»¥ng

### API Endpoints

#### 1. Main Chat endpoint (Hybrid Orchestrator)
```bash
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "OnePlus dÆ°á»›i 50 triá»‡u",
    "user_id": "user123",
    "session_id": "session001"
  }'
```

#### 2. Product Search (tá»« dataset thá»±c táº¿)
```bash
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Samsung Galaxy camera 50MP",
    "user_id": "user123",
    "session_id": "session001"
  }'
```

#### 3. Order Tracking
```bash
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ÄÆ¡n hÃ ng #1234 Ä‘ang á»Ÿ Ä‘Ã¢u?",
    "user_id": "user123",
    "session_id": "session001"
  }'
```

#### 4. Health check
```bash
curl http://localhost:8000/health
```

#### 5. Hybrid Orchestrator Metrics
```bash
curl http://localhost:8000/metrics
```

#### 6. Monitoring Dashboard (NEW)
```bash
curl http://localhost:8000/dashboard
```

#### 7. Request Traces (NEW)
```bash
curl http://localhost:8000/traces
```

#### 8. Training & Fine-tuning (NEW)
```bash
# Start training pipeline
curl -X POST "http://localhost:8000/training/start" \
  -H "Content-Type: application/json" \
  -d '{"data_source": "dataset", "auto_mode": false}'

# Get training status
curl http://localhost:8000/training/status

# Get training history
curl http://localhost:8000/training/history

# Prepare training data
curl -X POST http://localhost:8000/training/prepare-data

# Evaluate model
curl -X POST http://localhost:8000/training/evaluate

# Toggle auto-retrain
curl -X POST "http://localhost:8000/training/auto-retrain" \
  -H "Content-Type: application/json" \
  -d '{"enabled": true}'
```

#### 9. System Information
```bash
curl http://localhost:8000/
```

### Python SDK
```python
import asyncio
from core.router import AgnoRouter, RouterConfig

async def main():
    config = RouterConfig(
        rag_config={},
        interaction_config={},
        api_config={}
    )
    
    router = AgnoRouter(config)
    await router.initialize()
    
    response = await router.process_request(
        message="Xin chÃ o, tÃ´i cáº§n tÆ° váº¥n vá» Ä‘iá»‡n thoáº¡i",
        user_id="user123"
    )
    
    print(response["response"])
    
    await router.cleanup()

asyncio.run(main())
```

## ğŸ¯ TÃ­nh nÄƒng nÃ¢ng cao

### 1. CÃ¡ nhÃ¢n hÃ³a ngÆ°á»i dÃ¹ng
- Há»c há»i tá»« lá»‹ch sá»­ mua hÃ ng
- Gá»£i Ã½ sáº£n pháº©m phÃ¹ há»£p
- Reinforcement Learning tá»« feedback

### 2. Hybrid Orchestrator Architecture
- **Rule-based Router**: Fast, deterministic routing vá»›i pattern matching
- **ML-based Router**: Context-aware routing vá»›i intent classification
- **Decision Fusion Engine**: Káº¿t há»£p decisions vá»›i adaptive weights
- **RAG Agent**: Xá»­ lÃ½ tÃ¬m kiáº¿m sáº£n pháº©m tá»« dataset thá»±c táº¿
- **Conversation Agent**: Há»™i thoáº¡i chung vá»›i context awareness
- **API Agent**: TÃ­ch há»£p dá»‹ch vá»¥ bÃªn ngoÃ i
- **Performance Tracking**: Real-time metrics vÃ  monitoring

### 3. Real Dataset Integration
- **27,000+ sáº£n pháº©m Ä‘iá»‡n thoáº¡i thá»±c táº¿** tá»« OnePlus, Samsung, Apple, Xiaomi, Motorola, Realme, Nothing
- **ThÃ´ng sá»‘ chi tiáº¿t**: CPU, RAM, ROM, camera, pin, mÃ n hÃ¬nh, 5G, NFC, sáº¡c nhanh
- **GiÃ¡ cáº£ thá»±c táº¿**: Tá»« 19,989 VND Ä‘áº¿n hÃ ng triá»‡u VND
- **Rating vÃ  reviews** tá»« ngÆ°á»i dÃ¹ng thá»±c táº¿
- **Auto-conversion**: Tá»± Ä‘á»™ng convert format Ä‘á»ƒ phÃ¹ há»£p vá»›i RAG system

### 4. Caching thÃ´ng minh
- Redis cache cho production
- Memory cache cho development
- Cache responses vÃ  embeddings
- TTL vÃ  invalidation

### 5. Monitoring & Observability (Phase 6)
- **Enhanced Metrics System**: API latency, query counts, success/failure rates
- **Comprehensive Health Checks**: System resources, application health, load balancer support
- **Request Tracing**: OpenTelemetry/Jaeger integration vá»›i span tracking
- **Monitoring Dashboard**: Real-time performance visualization vá»›i `/dashboard` endpoint
- **Hybrid Orchestrator Metrics**: Rule-based vs ML-based vs hybrid performance tracking

### 6. Training & Fine-tuning (Phase 7)
- **E-commerce Data Pipeline**: Conversation normalization, intent detection, entity extraction
- **Model Fine-tuning**: TinyLlama + PEFT/LoRA cho domain e-commerce
- **Comprehensive Evaluation**: BLEU, ROUGE, intent accuracy, semantic similarity
- **Synthetic Data Generation**: TÄƒng cÆ°á»ng training data vá»›i variations
- **Continuous Improvement**: Model retraining tá»« conversation data

## ğŸ§ª Testing

```bash
# Cháº¡y táº¥t cáº£ tests
pytest

# Cháº¡y test cá»¥ thá»ƒ
pytest tests/test_router.py

# Cháº¡y vá»›i coverage
pytest --cov=core tests/
```

## ğŸ“Š Monitoring

### Health Check
```bash
curl http://localhost:8000/health
```

### Hybrid Orchestrator Metrics
```bash
curl http://localhost:8000/metrics
```

**Expected Response:**
```json
{
  "status": "success",
  "metrics": {
    "total_requests": 1000,
    "rule_based_requests": 200,
    "ml_based_requests": 300,
    "hybrid_requests": 500,
    "average_response_time": 145.2,
    "rule_based_percentage": 20.0,
    "ml_based_percentage": 30.0,
    "hybrid_percentage": 50.0
  },
  "orchestrator_type": "hybrid"
}
```

### Monitoring Dashboard (NEW)
```bash
curl http://localhost:8000/dashboard
```

**Expected Response:**
```json
{
  "status": "success",
  "timestamp": 1703123456.789,
  "dashboard": {
    "system_health": {
      "overall_status": "healthy",
      "health_score": 95.5,
      "uptime": 3600,
      "memory_usage_mb": 512.3,
      "cpu_usage_percent": 45.2
    },
    "performance_metrics": {
      "total_requests": 1000,
      "success_rate": 98.5,
      "error_rate": 1.5,
      "average_response_time": 145.2,
      "avg_rag_time": 89.3,
      "avg_conversation_time": 67.8,
      "avg_api_time": 234.1
    },
    "query_breakdown": {
      "total_queries": 1000,
      "rag_queries": 400,
      "conversation_queries": 350,
      "api_queries": 250,
      "rag_error_rate": 0.5,
      "conversation_error_rate": 1.2,
      "api_error_rate": 2.1
    },
    "router_performance": {
      "rule_based_requests": 200,
      "ml_based_requests": 300,
      "hybrid_requests": 500,
      "rule_based_percentage": 20.0,
      "ml_based_percentage": 30.0,
      "hybrid_percentage": 50.0
    },
    "tracing": {
      "active_traces": 5,
      "completed_traces": 995,
      "average_duration": 145.2,
      "max_duration": 2000.0,
      "min_duration": 50.0
    }
  }
}
```

### Tracing
```bash
curl http://localhost:8000/traces
```

## ğŸ“‹ Postman Testing

Xem file `DATASET_AND_POSTMAN_GUIDE.md` Ä‘á»ƒ cÃ³ hÆ°á»›ng dáº«n chi tiáº¿t vá» testing vá»›i Postman, bao gá»“m:

- **10+ test cases** vá»›i dataset thá»±c táº¿
- **Product search** vá»›i OnePlus, Samsung, Apple, Xiaomi, etc.
- **Order tracking** vÃ  API integration
- **Personalization testing** vá»›i user preferences
- **Hybrid Orchestrator testing** vá»›i rule-based vs ML-based routing
- **Performance testing** vá»›i cache vÃ  concurrent requests

### Quick Postman Tests

```bash
# Test OnePlus tá»« dataset thá»±c táº¿
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "OnePlus dÆ°á»›i 50 triá»‡u", "user_id": "user123"}'

# Test Samsung Galaxy
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "Samsung Galaxy camera 50MP", "user_id": "user123"}'

# Test Nothing Phone
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "Nothing Phone giÃ¡ ráº»", "user_id": "user123"}'
```

## ğŸ”„ Development

### Code Style
```bash
# Format code
black .

# Sort imports
isort .

# Lint code
flake8 .
```

### Pre-commit hooks
```bash
pip install pre-commit
pre-commit install
```

## ğŸ“ˆ Performance

### Caching
- Response caching giáº£m 80% thá»i gian pháº£n há»“i
- Embedding caching tÄƒng tá»‘c RAG
- Redis cluster cho high availability

### Scaling
- Horizontal scaling vá»›i multiple instances
- Load balancing
- Database sharding
- CDN cho static assets

## ğŸ¤ Contributing

1. Fork repository
2. Táº¡o feature branch
3. Commit changes
4. Push to branch
5. Táº¡o Pull Request

## ğŸ“„ License

MIT License - xem file LICENSE Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

## ğŸ†˜ Support

- Issues: [GitHub Issues](https://github.com/your-repo/issues)
- Discussions: [GitHub Discussions](https://github.com/your-repo/discussions)
- Email: support@your-domain.com

## ğŸ™ Acknowledgments

- Google Gemini API
- Groq API
- Ollama
- FastAPI
- Pydantic
- Redis
- Pinecone (Cloud Vector Database)