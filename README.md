# AI Agent System - Hybrid Orchestrator

Há»‡ thá»‘ng AI Agent thÃ´ng minh cho thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ vá»›i **Hybrid Orchestrator** káº¿t há»£p rule-based vÃ  ML-based routing, sá»­ dá»¥ng dataset thá»±c táº¿ vá»›i 27,000+ sáº£n pháº©m Ä‘iá»‡n thoáº¡i.

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## TÃ­nh nÄƒng chÃ­nh

- **Hybrid Orchestrator**: Káº¿t há»£p rule-based + ML-based routing (Ä‘á»™ chÃ­nh xÃ¡c 85-95%)
- **Dataset thá»±c táº¿**: ~900 sáº£n pháº©m Ä‘iá»‡n thoáº¡i tá»« OnePlus, Samsung, Apple, Xiaomi, etc.
- **RAG System**: TÃ¬m kiáº¿m ngá»¯ nghÄ©a vá»›i Pinecone vector database
- **Há»™i thoáº¡i thÃ´ng minh**: TÆ°Æ¡ng tÃ¡c tá»± nhiÃªn vá»›i context-aware routing
- **API Integration**: Káº¿t ná»‘i vá»›i microservices (Ä‘Æ¡n hÃ ng, thanh toÃ¡n, báº£o hÃ nh)
- **CÃ¡ nhÃ¢n hÃ³a**: Há»c há»i tá»« hÃ nh vi ngÆ°á»i dÃ¹ng vÃ  Ä‘Æ°a ra gá»£i Ã½ phÃ¹ há»£p
- **Multi-model**: Há»— trá»£ nhiá»u LLM (Gemini, Groq, Ollama, OpenAI, Claude)
- **Caching**: Há»‡ thá»‘ng cache thÃ´ng minh vá»›i Redis vÃ  Memory cache
- **Monitoring**: Theo dÃµi hiá»‡u suáº¥t real-time vá»›i dashboard chi tiáº¿t
- **Training**: Fine-tune model cho domain e-commerce vá»›i data pipeline hoÃ n chá»‰nh

## Kiáº¿n trÃºc há»‡ thá»‘ng

### Hybrid Orchestrator Architecture
```mermaid
graph TB
    A[Client Request] --> B[FastAPI App]
    B --> C[AgnoRouter - Hybrid Orchestrator]
    
    C --> D[Rule-based Router]
    C --> E[ML-based Router]
    
    D --> F[Pattern Matching]
    E --> G[Intent Classification]
    
    F --> H[Decision Fusion Engine]
    G --> H
    
    H --> I{Intent Decision}
    
    I -->|search| J[RAG Agent]
    I -->|chat| K[Conversation Agent]
    I -->|api| L[API Agent]
    
    J --> M[Pinecone Vector Search]
    M --> N[Product Results]
    N --> O[Personalization]
    O --> P[Natural Language Response]
    
    K --> Q[LLM Model]
    Q --> R[Context-aware Response]
    
    L --> S[External APIs]
    S --> T[API Response]
    
    P --> U[Cache Manager]
    R --> U
    T --> U
    
    U --> V[Response to Client]
```

## Cáº¥u trÃºc thÆ° má»¥c

```
ai_agent/
â”œâ”€â”€ app.py                        # FastAPI entry point
â”œâ”€â”€ config.py                     # Configuration management
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ env.example                   # Environment variables template
â”œâ”€â”€ init_data.py                  # Data initialization
â”‚
â”œâ”€â”€ core/                         # Core logic (Hybrid Orchestrator)
â”‚   â”œâ”€â”€ models/                   # Agent models
â”‚   â”‚   â”œâ”€â”€ base_agent.py         # Base agent class
â”‚   â”‚   â”œâ”€â”€ rag_agent.py          # RAG-specific agent
â”‚   â”‚   â”œâ”€â”€ conversation_agent.py # Conversation agent
â”‚   â”‚   â”œâ”€â”€ api_agent.py          # API integration agent
â”‚   â”‚   â””â”€â”€ orchestrator.py       # Agent orchestrator
â”‚   â”œâ”€â”€ router.py                 # Hybrid Orchestrator
â”‚   â”œâ”€â”€ rag_model.py              # RAG model implementation
â”‚   â”œâ”€â”€ interaction_model.py      # Conversation model
â”‚   â”œâ”€â”€ api_model.py              # API model
â”‚   â”œâ”€â”€ personalization_model.py  # Personalization model
â”‚   â””â”€â”€ prompts.py                # Prompt templates
â”‚
â”œâ”€â”€ adapters/                     # Adapter layer
â”‚   â”œâ”€â”€ model_loader/             # Model loaders
â”‚   â”‚   â”œâ”€â”€ base_loader.py        # Base loader
â”‚   â”‚   â”œâ”€â”€ gemini_loader.py      # Google Gemini
â”‚   â”‚   â”œâ”€â”€ groq_loader.py        # Groq API
â”‚   â”‚   â”œâ”€â”€ ollama_loader.py      # Ollama local
â”‚   â”‚   â””â”€â”€ openai_loader.py      # OpenAI GPT
â”‚   â””â”€â”€ pinecone_client.py        # Pinecone vector DB
â”‚
â”œâ”€â”€ cache/                        # Caching layer
â”‚   â”œâ”€â”€ redis_cache.py            # Redis cache
â”‚   â”œâ”€â”€ memory_cache.py           # In-memory cache
â”‚   â””â”€â”€ cache_manager.py          # Cache manager
â”‚
â”œâ”€â”€ monitoring/                   # Monitoring & observability
â”‚   â”œâ”€â”€ metrics.py                # Metrics collection
â”‚   â”œâ”€â”€ health_check.py           # Health monitoring
â”‚   â””â”€â”€ tracing.py                # Request tracing
â”‚
â”œâ”€â”€ personalization/              # Personalization layer
â”‚   â”œâ”€â”€ profile_manager.py        # User profile management
â”‚   â”œâ”€â”€ recommender.py            # Product recommendations
â”‚   â””â”€â”€ rl_feedback.py            # Reinforcement learning
â”‚
â”œâ”€â”€ services/                     # Microservices integration
â”‚   â”œâ”€â”€ product_service.py        # Product API
â”‚   â”œâ”€â”€ order_service.py          # Order API
â”‚   â”œâ”€â”€ payment_service.py        # Payment API
â”‚   â”œâ”€â”€ warranty_service.py       # Warranty API
â”‚   â””â”€â”€ mock/                     # Mock services
â”‚       â”œâ”€â”€ mock_order.json
â”‚       â”œâ”€â”€ mock_warranty.json
â”‚       â””â”€â”€ mock_payment.json
â”‚
â”œâ”€â”€ data/                         # Data management
â”‚   â”œâ”€â”€ ingest.py                 # Data ingestion
â”‚   â”œâ”€â”€ process_dataset.py        # Dataset processing
â”‚   â”œâ”€â”€ processed/                # Processed data
â”‚   â”œâ”€â”€ profiles/                 # User profiles
â”‚   â””â”€â”€ schema/                   # Data schemas
â”‚
â”œâ”€â”€ training/                     # Model training & fine-tuning
â”‚   â”œâ”€â”€ dataset/                  # Real dataset
â”‚   â”‚   â””â”€â”€ dataset.json          # 27,000+ real phone products
â”‚   â”œâ”€â”€ prepare_data.py           # Data preparation
â”‚   â”œâ”€â”€ finetune.py               # Model fine-tuning
â”‚   â”œâ”€â”€ evaluate.py               # Model evaluation
â”‚   â””â”€â”€ training_pipeline.py      # Training pipeline
â”‚
â””â”€â”€ utils/                        # Utilities
    â”œâ”€â”€ logger.py                 # Logging utilities
    â””â”€â”€ helpers.py                # Helper functions
```

## CÃ i Ä‘áº·t

### 1. Clone repository
```bash
git clone <repository-url>
cd ai_agent
```

### 2. Táº¡o virtual environment
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate     # Windows
```

### 3. CÃ i Ä‘áº·t dependencies

#### TÃ¹y chá»n 1: CÃ i Ä‘áº·t Ä‘áº§y Ä‘á»§ (khuyáº¿n nghá»‹)
```bash
pip install -r requirements.txt
```

#### TÃ¹y chá»n 2: CÃ i Ä‘áº·t tá»‘i thiá»ƒu (chá»‰ core features)
```bash
pip install fastapi uvicorn pydantic pydantic-settings google-generativeai pinecone-client redis httpx python-dotenv psutil
```

#### TÃ¹y chá»n 3: CÃ i Ä‘áº·t cho development
```bash
pip install -r requirements.txt black isort flake8 mypy pytest pytest-asyncio pytest-cov
```

### 4. Cáº¥u hÃ¬nh environment
```bash
cp env.example .env
# Chá»‰nh sá»­a .env vá»›i API keys cá»§a báº¡n
# QUAN TRá»ŒNG: Cáº§n cÃ³ PINECONE_API_KEY Ä‘á»ƒ sá»­ dá»¥ng vector database
```

### 5. Khá»Ÿi táº¡o dá»¯ liá»‡u vá»›i dataset thá»±c táº¿
```bash
# Load 27,000+ sáº£n pháº©m Ä‘iá»‡n thoáº¡i thá»±c táº¿ vÃ o Pinecone
python init_data.py
```

### 6. Cháº¡y á»©ng dá»¥ng
```bash
python app.py
```

## Requirements

### CÃ¡c file requirements

1. **`requirements.txt`** - CÃ i Ä‘áº·t Ä‘áº§y Ä‘á»§ (khuyáº¿n nghá»‹)
   - Táº¥t cáº£ AI APIs (Gemini, Groq, Ollama, OpenAI, Claude)
   - Vector database (Pinecone cloud only)
   - Caching (Redis, Memory cache)
   - Monitoring & observability
   - Personalization & ML
   - Development tools

2. **`requirements-minimal.txt`** - CÃ i Ä‘áº·t tá»‘i thiá»ƒu
   - Chá»‰ core features cáº§n thiáº¿t
   - Free APIs (Gemini, Groq, Ollama)
   - FAISS vector database
   - Redis caching
   - KÃ­ch thÆ°á»›c: ~500MB

3. **`requirements-dev.txt`** - Development
   - Bao gá»“m táº¥t cáº£ requirements.txt
   - Testing tools (pytest, coverage)
   - Code quality (black, flake8, mypy)
   - Debugging tools
   - Documentation tools

### So sÃ¡nh kÃ­ch thÆ°á»›c cÃ i Ä‘áº·t

| File | KÃ­ch thÆ°á»›c | Thá»i gian cÃ i Ä‘áº·t | TÃ­nh nÄƒng |
|------|------------|-------------------|-----------|
| requirements-minimal.txt | ~500MB | 2-3 phÃºt | Core only |
| requirements.txt | ~2GB | 5-10 phÃºt | Full features |
| requirements-dev.txt | ~2.5GB | 8-15 phÃºt | Full + Dev tools |

## Cáº¥u hÃ¬nh

### API Keys (Miá»…n phÃ­)
- **Gemini API**: Láº¥y tá»« [Google AI Studio](https://makersuite.google.com/app/apikey)
- **Groq API**: Láº¥y tá»« [Groq Console](https://console.groq.com/)
- **Ollama**: CÃ i Ä‘áº·t local tá»« [Ollama.ai](https://ollama.ai/)

### Environment Variables
```bash
# Free APIs
GEMINI_API_KEY=your_gemini_api_key
GROQ_API_KEY=your_groq_api_key
OLLAMA_BASE_URL=http://localhost:11434

# Optional APIs
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
PINECONE_API_KEY=your_pinecone_api_key

# Configuration
MODEL_LOADER_BACKEND=gemini  # gemini, groq, ollama, openai, claude
ENABLE_PERSONALIZATION=true
ENABLE_RECOMMENDATIONS=true
ENABLE_RL_LEARNING=true
```

## Sá»­ dá»¥ng

### API Endpoints

#### 1. Main Chat endpoint (Hybrid Orchestrator)
```bash
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "OnePlus dÆ°á»›i 50 triá»‡u",
    "user_id": "user123",
    "session_id": "session001"
  }'
```

#### 2. Product Search (tá»« dataset thá»±c táº¿)
```bash
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Samsung Galaxy camera 50MP",
    "user_id": "user123",
    "session_id": "session001"
  }'
```

#### 3. Order Tracking
```bash
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ÄÆ¡n hÃ ng #1234 Ä‘ang á»Ÿ Ä‘Ã¢u?",
    "user_id": "user123",
    "session_id": "session001"
  }'
```

#### 4. Health check
```bash
curl http://localhost:8000/health
```

#### 5. Hybrid Orchestrator Metrics
```bash
curl http://localhost:8000/metrics
```

#### 6. Monitoring Dashboard (NEW)
```bash
curl http://localhost:8000/dashboard
```

#### 7. Request Traces (NEW)
```bash
curl http://localhost:8000/traces
```

#### 8. Training & Fine-tuning (NEW)
```bash
# Start training pipeline
curl -X POST "http://localhost:8000/training/start" \
  -H "Content-Type: application/json" \
  -d '{"data_source": "dataset", "auto_mode": false}'

# Get training status
curl http://localhost:8000/training/status

# Get training history
curl http://localhost:8000/training/history

# Prepare training data
curl -X POST http://localhost:8000/training/prepare-data

# Evaluate model
curl -X POST http://localhost:8000/training/evaluate

# Toggle auto-retrain
curl -X POST "http://localhost:8000/training/auto-retrain" \
  -H "Content-Type: application/json" \
  -d '{"enabled": true}'
```

#### 9. System Information
```bash
curl http://localhost:8000/
```

### Python SDK
```python
import asyncio
from core.router import AgnoRouter, RouterConfig

async def main():
    config = RouterConfig(
        rag_config={},
        interaction_config={},
        api_config={}
    )
    
    router = AgnoRouter(config)
    await router.initialize()
    
    response = await router.process_request(
        message="Xin chÃ o, tÃ´i cáº§n tÆ° váº¥n vá» Ä‘iá»‡n thoáº¡i",
        user_id="user123"
    )
    
    print(response["response"])
    
    await router.cleanup()

asyncio.run(main())
```

## TÃ­nh nÄƒng nÃ¢ng cao

### 1. CÃ¡ nhÃ¢n hÃ³a ngÆ°á»i dÃ¹ng
- Há»c há»i tá»« lá»‹ch sá»­ mua hÃ ng
- Gá»£i Ã½ sáº£n pháº©m phÃ¹ há»£p
- Reinforcement Learning tá»« feedback

### 2. Hybrid Orchestrator Architecture
- **Rule-based Router**: Fast, deterministic routing vá»›i pattern matching
- **ML-based Router**: Context-aware routing vá»›i intent classification
- **Decision Fusion Engine**: Káº¿t há»£p decisions vá»›i adaptive weights
- **RAG Agent**: Xá»­ lÃ½ tÃ¬m kiáº¿m sáº£n pháº©m tá»« dataset thá»±c táº¿
- **Conversation Agent**: Há»™i thoáº¡i chung vá»›i context awareness
- **API Agent**: TÃ­ch há»£p dá»‹ch vá»¥ bÃªn ngoÃ i
- **Performance Tracking**: Real-time metrics vÃ  monitoring

### 3. Real Dataset Integration
- **27,000+ sáº£n pháº©m Ä‘iá»‡n thoáº¡i thá»±c táº¿** tá»« OnePlus, Samsung, Apple, Xiaomi, Motorola, Realme, Nothing
- **ThÃ´ng sá»‘ chi tiáº¿t**: CPU, RAM, ROM, camera, pin, mÃ n hÃ¬nh, 5G, NFC, sáº¡c nhanh
- **GiÃ¡ cáº£ thá»±c táº¿**: Tá»« 19,989 VND Ä‘áº¿n hÃ ng triá»‡u VND
- **Rating vÃ  reviews** tá»« ngÆ°á»i dÃ¹ng thá»±c táº¿
- **Auto-conversion**: Tá»± Ä‘á»™ng convert format Ä‘á»ƒ phÃ¹ há»£p vá»›i RAG system

### 4. Caching thÃ´ng minh
- Redis cache cho production
- Memory cache cho development
- Cache responses vÃ  embeddings
- TTL vÃ  invalidation

### 5. Monitoring & Observability (Phase 6)
- **Enhanced Metrics System**: API latency, query counts, success/failure rates
- **Comprehensive Health Checks**: System resources, application health, load balancer support
- **Request Tracing**: OpenTelemetry/Jaeger integration vá»›i span tracking
- **Monitoring Dashboard**: Real-time performance visualization vá»›i `/dashboard` endpoint
- **Hybrid Orchestrator Metrics**: Rule-based vs ML-based vs hybrid performance tracking

### 6. Training & Fine-tuning (Phase 7)
- **E-commerce Data Pipeline**: Conversation normalization, intent detection, entity extraction
- **Model Fine-tuning**: TinyLlama + PEFT/LoRA cho domain e-commerce
- **Comprehensive Evaluation**: BLEU, ROUGE, intent accuracy, semantic similarity
- **Synthetic Data Generation**: TÄƒng cÆ°á»ng training data vá»›i variations
- **Continuous Improvement**: Model retraining tá»« conversation data

## Testing

```bash
# Cháº¡y táº¥t cáº£ tests
pytest

# Cháº¡y test cá»¥ thá»ƒ
pytest tests/test_router.py

# Cháº¡y vá»›i coverage
pytest --cov=core tests/
```

## Monitoring

### Health Check
```bash
curl http://localhost:8000/health
```

### Hybrid Orchestrator Metrics
```bash
curl http://localhost:8000/metrics
```

**Expected Response:**
```json
{
  "status": "success",
  "metrics": {
    "total_requests": 1000,
    "rule_based_requests": 200,
    "ml_based_requests": 300,
    "hybrid_requests": 500,
    "average_response_time": 145.2,
    "rule_based_percentage": 20.0,
    "ml_based_percentage": 30.0,
    "hybrid_percentage": 50.0
  },
  "orchestrator_type": "hybrid"
}
```

### Monitoring Dashboard (NEW)
```bash
curl http://localhost:8000/dashboard
```

**Expected Response:**
```json
{
  "status": "success",
  "timestamp": 1703123456.789,
  "dashboard": {
    "system_health": {
      "overall_status": "healthy",
      "health_score": 95.5,
      "uptime": 3600,
      "memory_usage_mb": 512.3,
      "cpu_usage_percent": 45.2
    },
    "performance_metrics": {
      "total_requests": 1000,
      "success_rate": 98.5,
      "error_rate": 1.5,
      "average_response_time": 145.2,
      "avg_rag_time": 89.3,
      "avg_conversation_time": 67.8,
      "avg_api_time": 234.1
    },
    "query_breakdown": {
      "total_queries": 1000,
      "rag_queries": 400,
      "conversation_queries": 350,
      "api_queries": 250,
      "rag_error_rate": 0.5,
      "conversation_error_rate": 1.2,
      "api_error_rate": 2.1
    },
    "router_performance": {
      "rule_based_requests": 200,
      "ml_based_requests": 300,
      "hybrid_requests": 500,
      "rule_based_percentage": 20.0,
      "ml_based_percentage": 30.0,
      "hybrid_percentage": 50.0
    },
    "tracing": {
      "active_traces": 5,
      "completed_traces": 995,
      "average_duration": 145.2,
      "max_duration": 2000.0,
      "min_duration": 50.0
    }
  }
}
```

### Tracing
```bash
curl http://localhost:8000/traces
```

## Testing vá»›i Postman

### Test Cases vá»›i Dataset Thá»±c Táº¿

#### 1. **Product Search Tests**
```bash
# Test OnePlus tá»« dataset thá»±c táº¿
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "OnePlus dÆ°á»›i 50 triá»‡u", "user_id": "user123"}'

# Test Samsung Galaxy
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "Samsung Galaxy camera 50MP", "user_id": "user123"}'

# Test Nothing Phone
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "Nothing Phone giÃ¡ ráº»", "user_id": "user123"}'

# Test Apple iPhone
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "iPhone 15 Pro Max 256GB", "user_id": "user123"}'
```

#### 2. **Conversation Tests**
```bash
# Test há»™i thoáº¡i chung
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "Xin chÃ o, báº¡n cÃ³ thá»ƒ giÃºp tÃ´i khÃ´ng?", "user_id": "user123"}'

# Test tÆ° váº¥n sáº£n pháº©m
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "TÃ´i cáº§n Ä‘iá»‡n thoáº¡i chá»¥p áº£nh Ä‘áº¹p", "user_id": "user123"}'
```

#### 3. **API Integration Tests**
```bash
# Test tracking Ä‘Æ¡n hÃ ng
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "ÄÆ¡n hÃ ng #1234 Ä‘ang á»Ÿ Ä‘Ã¢u?", "user_id": "user123"}'

# Test thanh toÃ¡n
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "TÃ´i muá»‘n thanh toÃ¡n Ä‘Æ¡n hÃ ng", "user_id": "user123"}'
```

#### 4. **Performance Tests**
```bash
# Test health check
curl http://localhost:8000/health

# Test metrics
curl http://localhost:8000/metrics

# Test dashboard
curl http://localhost:8000/dashboard
```

### Postman Collection

Táº¡o Postman collection vá»›i cÃ¡c request sau:

1. **Environment Variables**:
   - `base_url`: `http://localhost:8000`
   - `user_id`: `user123`
   - `session_id`: `session001`

2. **Request Templates**:
   ```json
   {
     "message": "{{message}}",
     "user_id": "{{user_id}}",
     "session_id": "{{session_id}}",
     "context": {}
   }
   ```

3. **Test Scripts** (trong Postman Tests tab):
   ```javascript
   pm.test("Status code is 200", function () {
       pm.response.to.have.status(200);
   });
   
   pm.test("Response has required fields", function () {
       const jsonData = pm.response.json();
       pm.expect(jsonData).to.have.property('response');
       pm.expect(jsonData).to.have.property('intent');
       pm.expect(jsonData).to.have.property('confidence');
   });
   ```

## Development

### Code Style
```bash
# Format code
black .

# Sort imports
isort .

# Lint code
flake8 .
```

### Pre-commit hooks
```bash
pip install pre-commit
pre-commit install
```

## Performance

### Caching
- Response caching giáº£m 80% thá»i gian pháº£n há»“i
- Embedding caching tÄƒng tá»‘c RAG
- Redis cluster cho high availability

### Scaling
- Horizontal scaling vá»›i multiple instances
- Load balancing
- Database sharding
- CDN cho static assets

## FAQ

### Q: LÃ m tháº¿ nÃ o Ä‘á»ƒ thay Ä‘á»•i model LLM?
A: Cáº­p nháº­t biáº¿n mÃ´i trÆ°á»ng `MODEL_LOADER_BACKEND` trong file `.env`:
```bash
MODEL_LOADER_BACKEND=gemini  # hoáº·c groq, ollama, openai
```

### Q: LÃ m tháº¿ nÃ o Ä‘á»ƒ thÃªm dataset sáº£n pháº©m má»›i?
A: Thay tháº¿ file `training/dataset/dataset.json` vÃ  cháº¡y:
```bash
python init_data.py
```

### Q: LÃ m tháº¿ nÃ o Ä‘á»ƒ báº­t/táº¯t personalization?
A: Cáº­p nháº­t trong file `.env`:
```bash
ENABLE_PERSONALIZATION=true
ENABLE_RECOMMENDATIONS=true
```

### Q: LÃ m tháº¿ nÃ o Ä‘á»ƒ monitor hiá»‡u suáº¥t?
A: Sá»­ dá»¥ng cÃ¡c endpoint:
- `/health` - Health check
- `/metrics` - Metrics chi tiáº¿t
- `/dashboard` - Dashboard tá»•ng quan

### Q: LÃ m tháº¿ nÃ o Ä‘á»ƒ scale há»‡ thá»‘ng?
A: Sá»­ dá»¥ng load balancer vÃ  multiple instances vá»›i Redis cluster.

## Roadmap

### Phase 1: Core Features âœ…
- [x] Hybrid Orchestrator
- [x] RAG System vá»›i Pinecone
- [x] Multi-model support
- [x] Basic caching

### Phase 2: Advanced Features âœ…
- [x] Personalization system
- [x] API integration
- [x] Monitoring & observability
- [x] Training pipeline

### Phase 3: Production Ready ğŸ”„
- [ ] Docker containerization
- [ ] Kubernetes deployment
- [ ] Advanced security
- [ ] Rate limiting

### Phase 4: Enterprise Features ğŸ“‹
- [ ] Multi-tenant support
- [ ] Advanced analytics
- [ ] A/B testing
- [ ] Custom model training

## Contributing

ChÃºng tÃ´i hoan nghÃªnh má»i Ä‘Ã³ng gÃ³p! Vui lÃ²ng:

1. Fork repository
2. Táº¡o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Táº¡o Pull Request

### Development Guidelines
- TuÃ¢n thá»§ PEP 8 style guide
- Viáº¿t test cases cho code má»›i
- Cáº­p nháº­t documentation
- Sá»­ dá»¥ng conventional commits

## License

Distributed under the MIT License. See `LICENSE` for more information.

## Support & Contact

- **Email**: support@ai-agent.com
- **Issues**: [GitHub Issues](https://github.com/your-repo/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-repo/discussions)
- **Documentation**: [Wiki](https://github.com/your-repo/wiki)

## Acknowledgments

- [Google Gemini API](https://ai.google.dev/) - LLM capabilities
- [Groq API](https://groq.com/) - Fast inference
- [Ollama](https://ollama.ai/) - Local LLM hosting
- [FastAPI](https://fastapi.tiangolo.com/) - Web framework
- [Pinecone](https://www.pinecone.io/) - Vector database
- [Redis](https://redis.io/) - Caching layer
- [Pydantic](https://pydantic.dev/) - Data validation

---

<div align="center">

**Náº¿u dá»± Ã¡n nÃ y há»¯u Ã­ch, hÃ£y cho chÃºng tÃ´i má»™t star!**

Made with â¤ï¸ by AI Agent Team

</div>